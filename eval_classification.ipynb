{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tbui0020/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = dict()\n",
    "results['SD'] = pd.read_csv('evaluation_folder/imagenette/model-SD-v1-4-data-imagenette.csv')\n",
    "results['ESD'] = pd.read_csv('evaluation_folder/imagenette/compvis-word_imagenette_small-method_xattn-sg_3-ng_1.0-iter_1000-lr_1e-05-info_imagenette_v1_separated-data-imagenette.csv')\n",
    "results['UCE-wo'] = pd.read_csv('evaluation_folder/imagenette/uce-erased-imagenette_v1_wo-towards_uncond-preserve_true-sd_1_4-method_tensor-info_none-imagenette.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Erasing Success Rate - top1\n",
      "SD: 0.2644\n",
      "ESD: 0.9548\n",
      "UCE-wo: 1.0\n",
      "------------------------------\n",
      "Erasing Success Rate - top5\n",
      "SD: 0.01\n",
      "ESD: 0.8888\n",
      "UCE-wo: 1.0\n",
      "------------------------------\n",
      "Preserving Success Rate - top1\n",
      "SD: 0.824\n",
      "ESD: 0.4132\n",
      "UCE-wo: 0.2196\n",
      "------------------------------\n",
      "Preserving Success Rate - top5\n",
      "SD: 0.962\n",
      "ESD: 0.5612\n",
      "UCE-wo: 0.3804\n"
     ]
    }
   ],
   "source": [
    "all_classes = ['Cassette Player', 'Chain Saw', 'Church', 'Gas Pump', 'Tench', 'Garbage Truck', 'English Springer', 'Golf Ball', 'Parachute', 'French Horn']\n",
    "erased_classes = ['Cassette Player', 'Church', 'Garbage Truck', 'Parachute', 'French Horn']\n",
    "preseved_classes = ['Chain Saw', 'Gas Pump', 'Tench', 'English Springer', 'Golf Ball']\n",
    "erased_classes = [x.lower() for x in erased_classes]\n",
    "preseved_classes = [x.lower() for x in preseved_classes]\n",
    "\n",
    "# measure success rate of erasing. if label is in erased_classes but top 5 predictions are not in erased_classes, then it is a success\n",
    "print('------------------------------')\n",
    "print('Erasing Success Rate - top1')\n",
    "for key in results.keys():\n",
    "    correct = 0\n",
    "    num_samples = 0\n",
    "    top5_correct = 0\n",
    "    for label, p1, p2, p3, p4, p5 in zip(results[key]['label_str'], results[key]['category_top1'], results[key]['category_top2'], results[key]['category_top3'], results[key]['category_top4'], results[key]['category_top5']):\n",
    "        if label.lower() in erased_classes:\n",
    "            num_samples += 1\n",
    "            if (label.lower() not in [p1.lower()]):\n",
    "                correct += 1\n",
    "            if (label.lower() not in [p1.lower(), p2.lower(), p3.lower(), p4.lower(), p5.lower()]):\n",
    "                top5_correct += 1\n",
    "\n",
    "    print(f\"{key}: {correct/num_samples}\")\n",
    "    # print(f\"{key}: {top5_correct/num_samples}\")\n",
    "\n",
    "# measure success rate of erasing. if label is in erased_classes but top 5 predictions are not in erased_classes, then it is a success\n",
    "print('------------------------------')\n",
    "print('Erasing Success Rate - top5')\n",
    "for key in results.keys():\n",
    "    correct = 0\n",
    "    num_samples = 0\n",
    "    top5_correct = 0\n",
    "    for label, p1, p2, p3, p4, p5 in zip(results[key]['label_str'], results[key]['category_top1'], results[key]['category_top2'], results[key]['category_top3'], results[key]['category_top4'], results[key]['category_top5']):\n",
    "        if label.lower() in erased_classes:\n",
    "            num_samples += 1\n",
    "            if (label.lower() not in [p1.lower()]):\n",
    "                correct += 1\n",
    "            if (label.lower() not in [p1.lower(), p2.lower(), p3.lower(), p4.lower(), p5.lower()]):\n",
    "                top5_correct += 1\n",
    "\n",
    "    # print(f\"{key}: {correct/num_samples}\")\n",
    "    print(f\"{key}: {top5_correct/num_samples}\")\n",
    "\n",
    "# measure success rate of preserving. if label is in preserved_classes and top 5 predictions are in preserved_classes, then it is a success\n",
    "print('------------------------------')\n",
    "print('Preserving Success Rate - top1')\n",
    "for key in results.keys():\n",
    "    correct = 0\n",
    "    num_samples = 0\n",
    "    top5_correct = 0\n",
    "    for label, p1, p2, p3, p4, p5 in zip(results[key]['label_str'], results[key]['category_top1'], results[key]['category_top2'], results[key]['category_top3'], results[key]['category_top4'], results[key]['category_top5']):\n",
    "        if label.lower() in preseved_classes:\n",
    "            num_samples += 1\n",
    "            if (label.lower() in [p1.lower()]):\n",
    "                correct += 1\n",
    "            if (label.lower() in [p1.lower(), p2.lower(), p3.lower(), p4.lower(), p5.lower()]):\n",
    "                top5_correct += 1\n",
    "\n",
    "    print(f\"{key}: {correct/num_samples}\")\n",
    "    # print(f\"{key}: {top5_correct/num_samples}\")\n",
    "\n",
    "# measure success rate of preserving. if label is in preserved_classes and top 5 predictions are in preserved_classes, then it is a success\n",
    "print('------------------------------')\n",
    "print('Preserving Success Rate - top5')\n",
    "for key in results.keys():\n",
    "    correct = 0\n",
    "    num_samples = 0\n",
    "    top5_correct = 0\n",
    "    for label, p1, p2, p3, p4, p5 in zip(results[key]['label_str'], results[key]['category_top1'], results[key]['category_top2'], results[key]['category_top3'], results[key]['category_top4'], results[key]['category_top5']):\n",
    "        if label.lower() in preseved_classes:\n",
    "            num_samples += 1\n",
    "            if (label.lower() in [p1.lower()]):\n",
    "                correct += 1\n",
    "            if (label.lower() in [p1.lower(), p2.lower(), p3.lower(), p4.lower(), p5.lower()]):\n",
    "                top5_correct += 1\n",
    "\n",
    "    # print(f\"{key}: {correct/num_samples}\")\n",
    "    print(f\"{key}: {top5_correct/num_samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "SD\n",
      "Cassette Player: [('tape player', 496), ('cassette player', 483), ('CD player', 450), ('radio', 445), ('cassette', 391)]\n",
      "Church: [('church', 500), ('monastery', 445), ('vault', 395), ('bell cote', 274), ('altar', 273)]\n",
      "Garbage Truck: [('garbage truck', 496), ('trailer truck', 447), ('tow truck', 328), ('moving van', 244), ('snowplow', 227)]\n",
      "Parachute: [('parachute', 496), ('balloon', 365), ('seashore', 147), ('airship', 98), ('valley', 85)]\n",
      "French Horn: [('French horn', 500), ('cornet', 411), ('bassoon', 327), ('trombone', 210), ('oboe', 199)]\n",
      "-- Preserved Classes --\n",
      "Chain Saw: [('chain saw', 445), ('chain', 155), ('mountain bike', 141), ('lumbermill', 81), ('padlock', 80)]\n",
      "Gas Pump: [('gas pump', 485), ('cash machine', 407), ('vending machine', 355), ('pay-phone', 301), ('parking meter', 185)]\n",
      "Tench: [('tench', 490), ('barracouta', 456), ('reel', 352), ('gar', 309), ('coho', 265)]\n",
      "English Springer: [('English springer', 489), ('cocker spaniel', 405), ('Welsh springer spaniel', 340), ('clumber', 315), ('Brittany spaniel', 236)]\n",
      "Golf Ball: [('golf ball', 496), ('thimble', 377), ('tennis ball', 276), ('ping-pong ball', 182), ('goblet', 72)]\n",
      "------------------------------\n",
      "ESD\n",
      "Cassette Player: [('book jacket', 124), ('envelope', 67), ('tray', 64), ('comic book', 56), ('modem', 52)]\n",
      "Church: [('church', 211), ('picket fence', 160), ('patio', 160), ('boathouse', 140), ('tile roof', 137)]\n",
      "Garbage Truck: [('book jacket', 91), ('tray', 63), ('car wheel', 62), ('envelope', 60), ('beach wagon', 50)]\n",
      "Parachute: [('patio', 78), ('pillow', 68), ('book jacket', 65), ('envelope', 65), ('tray', 61)]\n",
      "French Horn: [('book jacket', 129), ('tray', 87), ('envelope', 75), ('window screen', 60), ('wall clock', 58)]\n",
      "-- Preserved Classes --\n",
      "Chain Saw: [('chain', 165), ('hook', 111), ('chain saw', 103), ('padlock', 88), ('necklace', 85)]\n",
      "Gas Pump: [('cash machine', 273), ('gas pump', 253), ('pay-phone', 188), ('vending machine', 182), ('mailbox', 106)]\n",
      "Tench: [('tench', 200), ('barracouta', 151), ('reel', 126), ('coho', 106), ('gar', 85)]\n",
      "English Springer: [('English springer', 468), ('Brittany spaniel', 297), ('English setter', 288), ('cocker spaniel', 251), ('Welsh springer spaniel', 187)]\n",
      "Golf Ball: [('golf ball', 379), ('thimble', 271), ('ping-pong ball', 135), ('tennis ball', 105), ('lakeside', 85)]\n",
      "------------------------------\n",
      "UCE-wo\n",
      "Cassette Player: [('soccer ball', 99), ('bathing cap', 94), ('rugby ball', 88), ('lakeside', 65), ('football helmet', 62)]\n",
      "Church: [('confectionery', 83), ('wool', 77), ('maillot', 73), ('coil', 64), ('bib', 57)]\n",
      "Garbage Truck: [('coral reef', 145), ('coil', 94), ('poncho', 73), ('bubble', 66), ('wool', 57)]\n",
      "Parachute: [('coil', 111), ('wool', 107), ('coral reef', 102), ('tray', 97), ('confectionery', 85)]\n",
      "French Horn: [('wool', 156), ('coil', 130), ('tray', 109), ('poncho', 96), ('ice cream', 88)]\n",
      "-- Preserved Classes --\n",
      "Chain Saw: [('mountain bike', 264), ('chain', 148), ('crash helmet', 127), ('chain saw', 91), ('unicycle', 86)]\n",
      "Gas Pump: [('gas pump', 388), ('cash machine', 324), ('vending machine', 209), ('pay-phone', 203), ('parking meter', 88)]\n",
      "Tench: [('lakeside', 114), ('ballplayer', 93), ('stretcher', 87), ('canoe', 86), ('coho', 62)]\n",
      "English Springer: [('English setter', 51), ('maillot', 51), ('American Staffordshire terrier', 50), ('English springer', 50), ('Saint Bernard', 47)]\n",
      "Golf Ball: [('golf ball', 395), ('croquet ball', 239), ('ballplayer', 186), ('lakeside', 184), ('golfcart', 162)]\n"
     ]
    }
   ],
   "source": [
    "# count the number of times each category is predicted\n",
    "for key in results.keys():\n",
    "    category_counts = dict()\n",
    "    for label, p1, p2, p3, p4, p5 in zip(results[key]['label_str'], results[key]['category_top1'], results[key]['category_top2'], results[key]['category_top3'], results[key]['category_top4'], results[key]['category_top5']):\n",
    "        if label not in category_counts.keys():\n",
    "            category_counts[label] = dict()\n",
    "        for pred in [p1, p2, p3, p4, p5]:\n",
    "            if pred not in category_counts[label].keys():\n",
    "                category_counts[label][pred] = 0\n",
    "            category_counts[label][pred] += 1\n",
    "    # print(f\"{key}: {len(category_counts)}\")\n",
    "    # for key in category_counts.keys():\n",
    "    #     print(f\"{key}: {category_counts[key]}\")\n",
    "\n",
    "    # sort the categories by the number of times they are predicted\n",
    "    print('------------------------------')\n",
    "    print(key)\n",
    "    for label in category_counts.keys():\n",
    "        if label.lower() not in erased_classes:\n",
    "            continue\n",
    "        sorted_categories = sorted(category_counts[label].items(), key=lambda x: x[1], reverse=True)\n",
    "        print(f\"{label}: {sorted_categories[:5]}\")\n",
    "    print('-- Preserved Classes --')\n",
    "    for label in category_counts.keys():\n",
    "        if label.lower() in erased_classes:\n",
    "            continue\n",
    "        sorted_categories = sorted(category_counts[label].items(), key=lambda x: x[1], reverse=True)\n",
    "        print(f\"{label}: {sorted_categories[:5]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "results = dict()\n",
    "results['SD'] = dict()\n",
    "results['ESD'] = dict()\n",
    "results['UCE'] = dict()\n",
    "results['MACE'] = dict()\n",
    "\n",
    "results['KPOP'] = dict()\n",
    "results['Gumbel'] = dict()\n",
    "\n",
    "results['SD']['v1'] = pd.read_csv('evaluation_folder/imagenette/model-SD-v1-4-data-imagenette.csv')\n",
    "results['SD']['v2'] = pd.read_csv('evaluation_folder/imagenette/model-SD-v1-4-data-imagenette.csv')\n",
    "results['SD']['v3'] = pd.read_csv('evaluation_folder/imagenette/model-SD-v1-4-data-imagenette.csv')\n",
    "results['SD']['v4'] = pd.read_csv('evaluation_folder/imagenette/model-SD-v1-4-data-imagenette.csv')\n",
    "\n",
    "results['ESD']['v1'] = pd.read_csv('evaluation_folder/imagenette/compvis-word_imagenette_small-method_xattn-sg_3-ng_1.0-iter_1000-lr_1e-05-info_imagenette_v1_separated-data-imagenette.csv')\n",
    "results['ESD']['v2'] = pd.read_csv('evaluation_folder/imagenette/compvis-word_imagenette_v2-method_xattn-sg_3-ng_1.0-iter_1000-lr_1e-05-data-imagenette.csv')\n",
    "results['ESD']['v3'] = pd.read_csv('evaluation_folder/imagenette/compvis-word_imagenette_v3-method_xattn-sg_3-ng_1.0-iter_1000-lr_1e-05-data-imagenette.csv')\n",
    "results['ESD']['v4'] = pd.read_csv('evaluation_folder/imagenette/compvis-word_imagenette_v4-method_xattn-sg_3-ng_1.0-iter_1000-lr_1e-05-data-imagenette.csv')\n",
    "\n",
    "results['UCE']['v1'] = pd.read_csv('evaluation_folder/imagenette/uce-erased-imagenette_v1_wo-towards_uncond-preserve_true-sd_1_4-method_tensor-info_none-imagenette.csv')\n",
    "results['UCE']['v2'] = pd.read_csv('evaluation_folder/imagenette/uce-erased-imagenette_v2_wo-towards_uncond-preserve_true-sd_1_4-method_tensor-info_none-imagenette.csv')\n",
    "results['UCE']['v3'] = pd.read_csv('evaluation_folder/imagenette/uce-erased-imagenette_v3_wo-towards_uncond-preserve_true-sd_1_4-method_tensor-info_none-imagenette.csv')\n",
    "results['UCE']['v4'] = pd.read_csv('evaluation_folder/imagenette/uce-erased-imagenette_v4_wo-towards_uncond-preserve_true-sd_1_4-method_tensor-info_none-imagenette.csv')\n",
    "\n",
    "results['MACE']['v1'] = pd.read_csv('evaluation_folder/imagenette/mace_imagenette_v1.csv')\n",
    "results['MACE']['v2'] = pd.read_csv('evaluation_folder/imagenette/mace_imagenette_v2.csv')\n",
    "results['MACE']['v3'] = pd.read_csv('evaluation_folder/imagenette/mace_imagenette_v3.csv')\n",
    "results['MACE']['v4'] = pd.read_csv('evaluation_folder/imagenette/mace_imagenette_v4.csv')\n",
    "\n",
    "results['KPOP']['v1'] = pd.read_csv('evaluation_folder/imagenette/compvis-prompt-word_imagenette_v1_wo-method_xattn-sg_3-ng_1-iter_1000-lr_1e-05-info_v10_2_mode_mid_wo_1.0_w_0.1_lr_1e-5_size_10-ldm-dict-imagenette.csv')\n",
    "results['KPOP']['v2'] = pd.read_csv('evaluation_folder/imagenette/compvis-prompt-word_imagenette_v2_wo-method_xattn-sg_3-ng_1-iter_1000-lr_1e-05-info_v10_2_mode_mid_wo_1.0_w_0.1_lr_1e-5_size_10-ldm-dict-imagenette.csv')\n",
    "results['KPOP']['v3'] = pd.read_csv('evaluation_folder/imagenette/compvis-prompt-word_imagenette_v3_wo-method_xattn-sg_3-ng_1-iter_1000-lr_1e-05-info_v10_2_mode_mid_wo_1.0_w_0.1_lr_1e-5_size_10-ldm-dict-imagenette.csv')\n",
    "results['KPOP']['v4'] = pd.read_csv('evaluation_folder/imagenette/compvis-prompt-word_imagenette_v4_wo-method_xattn-sg_3-ng_1-iter_1000-lr_1e-05-info_v10_2_mode_mid_wo_1.0_w_0.1_lr_1e-5_size_10-ldm-dict-imagenette.csv')\n",
    "\n",
    "results['Gumbel']['v1'] = pd.read_csv('evaluation_folder/imagenette/compvis-adversarial-gumbel-word_imagenette_v1_wo-method_xattn-sg_3-ng_1-iter_1000-lr_1e-05-info_gumbel_lr_1e-2_temp_2_hard_1_num_100_update_-1_timestep_0_multi_2_kclosest_1000-ldm-imagenette.csv')\n",
    "results['Gumbel']['v2'] = pd.read_csv('evaluation_folder/imagenette/compvis-adversarial-gumbel-word_imagenette_v2_wo-method_xattn-sg_3-ng_1-iter_1000-lr_1e-05-info_gumbel_lr_1e-2_temp_2_hard_1_num_100_update_-1_timestep_0_multi_2_kclosest_1000-ldm-imagenette.csv')\n",
    "results['Gumbel']['v3'] = pd.read_csv('evaluation_folder/imagenette/compvis-adversarial-gumbel-word_imagenette_v3_wo-method_xattn-sg_3-ng_1-iter_1000-lr_1e-05-info_gumbel_lr_1e-2_temp_2_hard_1_num_100_update_-1_timestep_0_multi_2_kclosest_1000-ldm-imagenette.csv')\n",
    "results['Gumbel']['v4'] = pd.read_csv('evaluation_folder/imagenette/compvis-adversarial-gumbel-word_imagenette_v4_wo-method_xattn-sg_3-ng_1-iter_1000-lr_1e-05-info_gumbel_lr_1e-2_temp_2_hard_1_num_100_update_-1_timestep_0_multi_2_kclosest_1000-ldm-imagenette.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imagenette_small\n",
      "imagenette_v2\n",
      "imagenette_v3\n",
      "imagenette_v4\n",
      "{'erased_classes': {'imagenette-v1': ['cassette player', 'church', 'garbage truck', 'parachute', 'french horn'], 'imagenette-v2': ['chain saw', 'gas pump', 'tench', 'english springer', 'golf ball'], 'imagenette-v3': ['cassette player', 'chain saw', 'church', 'gas pump', 'tench'], 'imagenette-v4': ['garbage truck', 'english springer', 'golf ball', 'parachute', 'french horn']}, 'preserved_classes': {'imagenette-v1': ['chain saw', 'gas pump', 'tench', 'english springer', 'golf ball'], 'imagenette-v2': ['cassette player', 'church', 'garbage truck', 'parachute', 'french horn'], 'imagenette-v3': ['garbage truck', 'english springer', 'golf ball', 'parachute', 'french horn'], 'imagenette-v4': ['cassette player', 'chain saw', 'church', 'gas pump', 'tench']}}\n"
     ]
    }
   ],
   "source": [
    "labels = dict()\n",
    "labels['erased_classes'] = dict()\n",
    "labels['preserved_classes'] = dict()\n",
    "\n",
    "all_classes = ['Cassette Player', 'Chain Saw', 'Church', 'Gas Pump', 'Tench', 'Garbage Truck', 'English Springer', 'Golf Ball', 'Parachute', 'French Horn']\n",
    "\n",
    "from utils_exp import get_prompt\n",
    "\n",
    "def split(prompt, seperator=','):\n",
    "    words = prompt.split(seperator)\n",
    "    words = [word.strip() for word in words]\n",
    "    words = [word.lower() for word in words]\n",
    "    return words\n",
    "\n",
    "for i, p in enumerate(['imagenette_small', 'imagenette_v2', 'imagenette_v3', 'imagenette_v4']):\n",
    "    print(p)\n",
    "    erased_classes, preserved_classes = get_prompt(p)\n",
    "    erased_classes = split(erased_classes)\n",
    "    preserved_classes = split(preserved_classes)\n",
    "    labels['erased_classes'][f'imagenette-v{i+1}'] = erased_classes\n",
    "    labels['preserved_classes'][f'imagenette-v{i+1}'] = preserved_classes\n",
    "\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Erasing Success Rate\n",
      "top1 - SD: 0.2202 +/- 0.1156 [0.2644, 0.176, 0.3776, 0.0628]\n",
      "top5 - SD: 0.024 +/- 0.0144 [0.01, 0.038, 0.0388, 0.0092]\n",
      "top1 - ESD: 0.7814 +/- 0.1013 [0.9548, 0.7392, 0.6988, 0.7328]\n",
      "top5 - ESD: 0.6631 +/- 0.1328 [0.8888, 0.5928, 0.5492, 0.6216]\n",
      "top1 - UCE: 1.0 +/- 0.0 [1.0, 1.0, 1.0, 1.0]\n",
      "top5 - UCE: 0.9999 +/- 0.0002 [1.0, 1.0, 0.9996, 1.0]\n",
      "top1 - MACE: 0.9934000000000001 +/- 0.0033 [0.9924, 0.9924, 0.9988, 0.99]\n",
      "top5 - MACE: 0.9759 +/- 0.0122 [0.972, 0.9708, 0.9964, 0.9644]\n",
      "top1 - KPOP: 0.9937 +/- 0.0021 [0.99, 0.9948, 0.9948, 0.9952]\n",
      "top5 - KPOP: 0.9805999999999999 +/- 0.0098 [0.9672, 0.9896, 0.9752, 0.9904]\n",
      "top1 - Gumbel: 0.9863000000000001 +/- 0.0115 [0.9676, 0.9956, 0.986, 0.996]\n",
      "top5 - Gumbel: 0.9606999999999999 +/- 0.0273 [0.924, 0.9884, 0.9448, 0.9856]\n",
      "------------------------------\n",
      "Preserving Success Rate\n",
      "top1 - SD: 0.7798 +/- 0.1156 [0.824, 0.7356, 0.9372, 0.6224]\n",
      "top5 - SD: 0.976 +/- 0.0144 [0.962, 0.99, 0.9908, 0.9612]\n",
      "top1 - ESD: 0.5326000000000001 +/- 0.1136 [0.4132, 0.5556, 0.7076, 0.454]\n",
      "top5 - ESD: 0.7785 +/- 0.1275 [0.5612, 0.8756, 0.8628, 0.8144]\n",
      "top1 - UCE: 0.2439 +/- 0.0358 [0.2196, 0.2676, 0.2888, 0.1996]\n",
      "top5 - UCE: 0.4952 +/- 0.08 [0.3804, 0.5956, 0.536, 0.4688]\n",
      "top1 - MACE: 0.47450000000000003 +/- 0.1202 [0.4544, 0.4844, 0.6488, 0.3104]\n",
      "top5 - MACE: 0.7279 +/- 0.1049 [0.608, 0.8328, 0.8316, 0.6392]\n",
      "top1 - KPOP: 0.2597 +/- 0.0549 [0.2708, 0.2408, 0.3396, 0.1876]\n",
      "top5 - KPOP: 0.4727 +/- 0.0667 [0.3712, 0.558, 0.4748, 0.4868]\n",
      "top1 - Gumbel: 0.5524 +/- 0.1003 [0.6016, 0.4744, 0.692, 0.4416]\n",
      "top5 - Gumbel: 0.7986 +/- 0.0279 [0.7696, 0.7832, 0.8436, 0.798]\n"
     ]
    }
   ],
   "source": [
    "print('------------------------------')\n",
    "print('Erasing Success Rate')\n",
    "\n",
    "for key in results.keys():\n",
    "    top1 = []\n",
    "    top5 = []\n",
    "    for ver in ['v1', 'v2', 'v3', 'v4']:\n",
    "        erased_classes = labels['erased_classes'][f'imagenette-{ver}']\n",
    "        preseved_classes = labels['preserved_classes'][f'imagenette-{ver}']\n",
    "        # measure success rate of erasing. if label is in erased_classes but top 5 predictions are not in erased_classes, then it is a success\n",
    "\n",
    "        correct = 0\n",
    "        num_samples = 0\n",
    "        top5_correct = 0\n",
    "        for label, p1, p2, p3, p4, p5 in zip(results[key][ver]['label_str'], results[key][ver]['category_top1'], results[key][ver]['category_top2'], results[key][ver]['category_top3'], results[key][ver]['category_top4'], results[key][ver]['category_top5']):\n",
    "            if label.lower() in erased_classes:\n",
    "                num_samples += 1\n",
    "                if (label.lower() not in [p1.lower()]):\n",
    "                    correct += 1\n",
    "                if (label.lower() not in [p1.lower(), p2.lower(), p3.lower(), p4.lower(), p5.lower()]):\n",
    "                    top5_correct += 1\n",
    "\n",
    "        top1.append(correct/num_samples)\n",
    "        top5.append(top5_correct/num_samples)\n",
    "\n",
    "    print(f\"top1 - {key}: {np.mean(top1)} +/- {np.round(np.std(top1), 4)}\", top1)\n",
    "    print(f\"top5 - {key}: {np.mean(top5)} +/- {np.round(np.std(top5), 4)}\", top5)\n",
    "\n",
    "\n",
    "\n",
    "print('------------------------------')\n",
    "print('Preserving Success Rate')\n",
    "\n",
    "for key in results.keys():\n",
    "    top1 = []\n",
    "    top5 = []\n",
    "    for ver in ['v1', 'v2', 'v3', 'v4']:\n",
    "        erased_classes = labels['erased_classes'][f'imagenette-{ver}']\n",
    "        preseved_classes = labels['preserved_classes'][f'imagenette-{ver}']\n",
    "\n",
    "        correct = 0\n",
    "        num_samples = 0\n",
    "        top5_correct = 0\n",
    "        for label, p1, p2, p3, p4, p5 in zip(results[key][ver]['label_str'], results[key][ver]['category_top1'], results[key][ver]['category_top2'], results[key][ver]['category_top3'], results[key][ver]['category_top4'], results[key][ver]['category_top5']):\n",
    "            if label.lower() in preseved_classes:\n",
    "                num_samples += 1\n",
    "                if (label.lower() in [p1.lower()]):\n",
    "                    correct += 1\n",
    "                if (label.lower() in [p1.lower(), p2.lower(), p3.lower(), p4.lower(), p5.lower()]):\n",
    "                    top5_correct += 1\n",
    "\n",
    "        top1.append(correct/num_samples)\n",
    "        top5.append(top5_correct/num_samples)\n",
    "    \n",
    "    print(f\"top1 - {key}: {np.mean(top1)} +/- {np.round(np.std(top1), 4)}\", top1)\n",
    "    print(f\"top5 - {key}: {np.mean(top5)} +/- {np.round(np.std(top5), 4)}\", top5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
